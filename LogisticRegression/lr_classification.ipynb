{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic Classification w/ Binary Logistic Regression\n",
    "\n",
    "#### Dataset: https://www.kaggle.com/competitions/spaceship-titanic/overview\n",
    "##### Dataset License: https://creativecommons.org/licenses/by/4.0/\n",
    "\n",
    "###### Author: Cody Weaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lr import LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True  \n",
      "PassengerId      object\n",
      "HomePlanet       object\n",
      "CryoSleep        object\n",
      "Cabin            object\n",
      "Destination      object\n",
      "Age             float64\n",
      "VIP              object\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Name             object\n",
      "Transported        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load raw train dataset\n",
    "train_set = pd.read_csv('../data/train.csv')\n",
    "print(train_set.head())\n",
    "print(train_set.dtypes)\n",
    "\n",
    "# convert bool labels to 0-1\n",
    "def convert_labels(df, label_col='Transported'):\n",
    "    return df[label_col].apply(lambda l: 0 if l == False else 1)\n",
    "\n",
    "train_set['Transported'] = convert_labels(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using amount billed for amenities only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "amenities_data = train_set.copy()\n",
    "\n",
    "def normalize_amenity_data(df, col_names):\n",
    "    # normalize to mean zero and unit variance\n",
    "    for column in amenities_columns:\n",
    "        column_mean = amenities_data[column].mean()\n",
    "        column_std = amenities_data[column].std()\n",
    "        normalize = lambda x: (x - column_mean) / column_std\n",
    "        amenities_data[column] = normalize(amenities_data[column])\n",
    "\n",
    "    # fill in missing values for amenities\n",
    "    amenities_data[amenities_columns] = amenities_data[amenities_columns].fillna(0)\n",
    "    \n",
    "    return amenities_data[amenities_columns]\n",
    "\n",
    "amenities_data[amenities_columns] = normalize_amenity_data(train_set, amenities_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8693/8693 [00:00<00:00, 113241.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Loss for epoch 0: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8693/8693 [00:00<00:00, 107285.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Loss for epoch 1: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8693/8693 [00:00<00:00, 107941.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Loss for epoch 2: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8693/8693 [00:00<00:00, 112366.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Loss for epoch 3: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8693/8693 [00:00<00:00, 114163.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Loss for epoch 4: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "amenities_model = LogisticRegressionModel(dim=len(amenities_columns))\n",
    "num_epochs = 5\n",
    "amenities_model.fit_model(\n",
    "    amenities_data[amenities_columns].to_numpy(),\n",
    "    amenities_data['Transported'],\n",
    "    num_epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Amenities Model on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70, Precision: 0.64, Recall: 0.93\n"
     ]
    }
   ],
   "source": [
    "X = amenities_data[amenities_columns].to_numpy()\n",
    "Y = amenities_data['Transported']\n",
    "print('Accuracy: %.2f, Precision: %.2f, Recall: %.2f' % amenities_model.evaluate(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Feature Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin\n",
      "G/734/S     8\n",
      "B/11/S      7\n",
      "F/1411/P    7\n",
      "B/82/S      7\n",
      "G/981/S     7\n",
      "           ..\n",
      "G/543/S     1\n",
      "B/106/P     1\n",
      "G/542/S     1\n",
      "F/700/P     1\n",
      "G/559/P     1\n",
      "Name: count, Length: 6560, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(train_set[['PassengerId', 'Transported']])\n",
    "\n",
    "# normalize continuous numerical features\n",
    "NUMERICAL_FEATS = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "def normalize_numerical_feats(df, cols):\n",
    "    numerical_cols = df[cols].copy()\n",
    "\n",
    "    for col in cols:\n",
    "        mean = numerical_cols[col].mean()\n",
    "        std = numerical_cols[col].std()\n",
    "        \n",
    "        normalize = lambda x: (x - mean ) / std\n",
    "        numerical_cols[col] = numerical_cols[col].apply(normalize)\n",
    "\n",
    "    # fill in missing values with mean (0)\n",
    "    numerical_cols[cols].fillna(0)\n",
    "\n",
    "    return numerical_cols\n",
    "\n",
    "data[NUMERICAL_FEATS] = normalize_numerical_feats(train_set, NUMERICAL_FEATS)\n",
    "\n",
    "# convert boolean values to 0, 1\n",
    "BOOLEAN_FEATS = ['CryoSleep', 'VIP']\n",
    "\n",
    "def convert_bool_feats(df, cols):\n",
    "    boolean_cols = df[cols].copy()\n",
    "\n",
    "    convert_bool = lambda x: 1 if x else 0\n",
    "\n",
    "    for col in cols:\n",
    "        boolean_cols[col] = boolean_cols[col].apply(convert_bool)\n",
    "\n",
    "    # fill in missing values with 0\n",
    "    boolean_cols.fillna(0)\n",
    "\n",
    "    return boolean_cols\n",
    "\n",
    "data[BOOLEAN_FEATS] = convert_bool_feats(train_set, BOOLEAN_FEATS)\n",
    "\n",
    "print(train_set['Cabin'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
