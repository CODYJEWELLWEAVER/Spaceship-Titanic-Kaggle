{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic Classification w/ Binary Logistic Regression\n",
    "\n",
    "#### Dataset: https://www.kaggle.com/competitions/spaceship-titanic/overview\n",
    "##### Dataset License: https://creativecommons.org/licenses/by/4.0/\n",
    "\n",
    "###### Author: Cody Weaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lr import LogisticRegressionModel\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True  \n",
      "PassengerId      object\n",
      "HomePlanet       object\n",
      "CryoSleep        object\n",
      "Cabin            object\n",
      "Destination      object\n",
      "Age             float64\n",
      "VIP              object\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Name             object\n",
      "Transported        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load raw train dataset\n",
    "train_set = pd.read_csv('../data/train.csv')\n",
    "print(train_set.head())\n",
    "print(train_set.dtypes)\n",
    "\n",
    "# convert bool labels to 0-1\n",
    "def convert_labels(df, label_col='Transported'):\n",
    "    return df[label_col].apply(lambda l: 1 if l else 0)\n",
    "\n",
    "train_set['Transported'] = convert_labels(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using amount billed for amenities only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "amenities_data = train_set.copy()\n",
    "\n",
    "def normalize_amenity_data(df, col_names):\n",
    "    # normalize to mean zero and unit variance\n",
    "    for column in amenities_columns:\n",
    "        column_mean = amenities_data[column].mean()\n",
    "        column_std = amenities_data[column].std()\n",
    "        normalize = lambda x: (x - column_mean) / column_std\n",
    "        amenities_data[column] = normalize(amenities_data[column])\n",
    "\n",
    "    # fill in missing values for amenities\n",
    "    amenities_data[amenities_columns] = amenities_data[amenities_columns].fillna(0)\n",
    "    \n",
    "    return amenities_data[amenities_columns]\n",
    "\n",
    "amenities_data[amenities_columns] = normalize_amenity_data(train_set, amenities_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model and validate model on amenities dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Scores - acc: 0.49\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_folds = 5\n",
    "\n",
    "def cross_validate(X, Y, num_epochs, num_folds, ModelClass):\n",
    "    # shuffle data\n",
    "    X = X.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    cv_scores = []\n",
    "    X = X.to_numpy()\n",
    "    Y = Y.to_numpy()\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=101)\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(X, Y)):\n",
    "        X_train = X[train_idx]\n",
    "        Y_train = Y[train_idx]\n",
    "\n",
    "        X_test = X[test_idx]\n",
    "        Y_test = Y[test_idx]\n",
    "\n",
    "        model = ModelClass(silent=True)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            max_iter=100,\n",
    "        )\n",
    "\n",
    "        scores = model.evaluate(X_test, Y_test)\n",
    "        cv_scores.append(scores)\n",
    "\n",
    "    acc = np.mean(cv_scores)\n",
    "    print('Cross-Validated Scores - acc: %.2f' % acc)\n",
    "\n",
    "cross_validate(\n",
    "    amenities_data[amenities_columns],\n",
    "    amenities_data['Transported'],\n",
    "    num_epochs,\n",
    "    num_folds,\n",
    "    LogisticRegressionModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, using only the amenities billing data performs poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression using every feature, except for PassengerId, Name, and CabinNum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numerical_feats(df, cols):\n",
    "    numerical_cols = df[cols].copy()\n",
    "\n",
    "    for col in cols:\n",
    "        mean = numerical_cols[col].mean()\n",
    "        std = numerical_cols[col].std()\n",
    "        \n",
    "        normalize = lambda x: (x - mean ) / std\n",
    "        numerical_cols[col] = numerical_cols[col].apply(normalize)\n",
    "\n",
    "    # fill in missing values with mean (0)\n",
    "    numerical_cols[cols].fillna(0)\n",
    "\n",
    "    return numerical_cols\n",
    "\n",
    "def convert_bool_feats(df, cols):\n",
    "    boolean_cols = df[cols].copy()\n",
    "\n",
    "    convert_bool = lambda x: 1 if x else 0\n",
    "\n",
    "    for col in cols:\n",
    "        boolean_cols[col] = boolean_cols[col].apply(convert_bool)\n",
    "\n",
    "    # fill in missing values with 0\n",
    "    boolean_cols.fillna(0)\n",
    "\n",
    "    return boolean_cols\n",
    "\n",
    "def prepare_dataset(dataset, training):\n",
    "    if training:\n",
    "        data = pd.DataFrame(dataset[['PassengerId', 'Transported']])\n",
    "    else:\n",
    "        data = pd.DataFrame(dataset[['PassengerId']])\n",
    "\n",
    "    # normalize continuous numerical features\n",
    "    NUMERICAL_FEATS = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    data[NUMERICAL_FEATS] = normalize_numerical_feats(dataset, NUMERICAL_FEATS)\n",
    "    # convert boolean values to 0, 1\n",
    "    BOOLEAN_FEATS = ['CryoSleep', 'VIP']\n",
    "    data[BOOLEAN_FEATS] = convert_bool_feats(dataset, BOOLEAN_FEATS)\n",
    "\n",
    "    # convert nominal feats to numerical feats\n",
    "    # home planet\n",
    "    home_planet_dummies = pd.get_dummies(dataset['HomePlanet'], dtype=np.float64)\n",
    "    home_planet_dummies.fillna(0)\n",
    "    data[home_planet_dummies.columns] = home_planet_dummies\n",
    "\n",
    "    # destination\n",
    "    destination_dummies = pd.get_dummies(dataset['Destination'], dtype=np.float64)\n",
    "    destination_dummies.fillna(0)\n",
    "    data[destination_dummies.columns] = destination_dummies\n",
    "\n",
    "    # cabin (exclude cabin numbers)\n",
    "    cabin = dataset['Cabin']\n",
    "    cabin = cabin.apply(lambda cabin: str(cabin).split('/'))\n",
    "    cabin = pd.DataFrame(\n",
    "        cabin.to_list(), \n",
    "        index=cabin.index,\n",
    "        columns=['Deck', 'CabinNum', 'Side'])\n",
    "\n",
    "    deck = cabin['Deck']\n",
    "    side = cabin['Side']\n",
    "    \n",
    "    deck_dummies = pd.get_dummies(deck, dtype=np.float64)\n",
    "    deck_dummies = deck_dummies.drop('nan', axis=1)\n",
    "    deck_dummies.fillna(0)\n",
    "    data[deck_dummies.columns] = deck_dummies\n",
    "\n",
    "    side_dummies = pd.get_dummies(side, dtype=np.float64)\n",
    "    side_dummies.fillna(0)\n",
    "    data[side_dummies.columns] = side_dummies\n",
    "\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = prepare_dataset(train_set, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584263200276085\n",
      "[ 4.19499253e-01 -7.46235699e-01 -4.30652883e-01  1.24216340e+00\n",
      "  2.40729714e+00  1.14349414e+01 -5.65235063e-01 -3.20035933e+00\n",
      " -6.81521356e+00  2.99014566e+00 -1.70940782e+00  3.99821677e+00\n",
      " -6.33264513e-01  5.24339222e-01 -3.23621736e+00 -6.89090295e-01\n",
      " -4.90770202e+00 -6.62454379e-04  1.91331827e+00 -8.03864238e+00\n",
      " -3.18379268e-02 -3.41063379e+00 -3.07327091e-01 -7.40169695e+00]\n",
      "-3.785819188691545\n"
     ]
    }
   ],
   "source": [
    "# feature column names\n",
    "feature_data = data[data.columns.difference([\n",
    "    'PassengerId', 'Transported'\n",
    "])]\n",
    "\n",
    "model_dim = len(feature_data.columns)\n",
    "\n",
    "model = LogisticRegressionModel(model_dim, silent=True)\n",
    "model.fit(feature_data.to_numpy(), data['Transported'].to_numpy(), max_iter=20, fit_bias=True)\n",
    "print(model.evaluate(feature_data.to_numpy(), data['Transported'].to_numpy()))\n",
    "\n",
    "print(model.weights)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw test dataset\n",
    "test_set = pd.read_csv('../data/test.csv')\n",
    "\n",
    "test_data = prepare_dataset(test_set, training=False)\n",
    "\n",
    "test_features = test_data[test_data.columns.difference(['PassengerId'])]\n",
    "\n",
    "predictions = model.predict(test_features.to_numpy())\n",
    "predictions = pd.DataFrame(predictions.tolist(), columns=['Transported'])\n",
    "\n",
    "submission_data = pd.concat([test_set['PassengerId'].copy(), predictions], axis=1)\n",
    "submission_data['Transported'] = submission_data['Transported'].apply(lambda l: True if l else False)\n",
    "submission_data.to_csv('../submissions/lr_03-20.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
